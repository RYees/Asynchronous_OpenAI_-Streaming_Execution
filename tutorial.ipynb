{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Asynchronous Programming\n",
    "\n",
    "### Understanding Asynchronous Programming\n",
    "Asynchronous programming is a paradigm that allows for non-blocking operations. Unlike traditional synchronous programming where tasks are completed one after another, asynchronous programming enables the execution of multiple tasks effectively and efficiently, particularly in `I/O-bound` and high-latency operations. This approach is beneficial in web services and `API interactions`, where waiting for a response can lead to inefficiencies.\n",
    "\n",
    "### Advantages\n",
    "- **Non-blocking Operations**: Allows other parts of your program to run without waiting for a task to complete.\n",
    "- **Improved Performance**: Better utilization of system resources, especially in network or I/O bound tasks.\n",
    "- **Enhanced Responsiveness**: Applications remain responsive, especially in UI or server-side operations.\n",
    "\n",
    "### Real-world Applications\n",
    "- **Web Servers**: Handling multiple incoming HTTP requests.\n",
    "- **Data Fetching**: Simultaneous API requests or database queries.\n",
    "- **Real-Time Data Processing**: Streaming data processing in chatbots or live feeds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Synchronous vs. Asynchronous Data Fetching\n",
    "\n",
    "### Synchronous Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronous Data Fetching Start\n",
      "Fetching data from API 1... (delay: 3 seconds)\n",
      "Received data from API 1!\n",
      "Fetching data from API 2... (delay: 2 seconds)\n",
      "Received data from API 2!\n",
      "Synchronous Data Fetching End\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def fetch_data_sync(api_name, delay):\n",
    "    print(f\"Fetching data from {api_name}... (delay: {delay} seconds)\")\n",
    "    time.sleep(delay)\n",
    "    print(f\"Received data from {api_name}!\")\n",
    "\n",
    "def run_sync_fetches():\n",
    "    print(\"Synchronous Data Fetching Start\")\n",
    "    fetch_data_sync(\"API 1\", 3)\n",
    "    fetch_data_sync(\"API 2\", 2)\n",
    "    print(\"Synchronous Data Fetching End\")\n",
    "\n",
    "run_sync_fetches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, the `fetch_data_sync` function simulates fetching data synchronously. Notice how the program waits for each API call to complete before moving to the next one. This leads to a total delay of 5 seconds, the sum of both API call delays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Data Fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asynchronous Data Fetching Start\n",
      "Fetching data from API 1 asynchronously... (delay: 3 seconds)\n",
      "Fetching data from API 2 asynchronously... (delay: 2 seconds)\n",
      "Received data from API 2 asynchronously!\n",
      "Received data from API 1 asynchronously!\n",
      "Asynchronous Data Fetching End\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "async def fetch_data_async(api_name, delay):\n",
    "    print(f\"Fetching data from {api_name} asynchronously... (delay: {delay} seconds)\")\n",
    "    await asyncio.sleep(delay)\n",
    "    print(f\"Received data from {api_name} asynchronously!\")\n",
    "\n",
    "async def run_async_fetches():\n",
    "    print(\"Asynchronous Data Fetching Start\")\n",
    "    await asyncio.gather(\n",
    "        fetch_data_async(\"API 1\", 3),\n",
    "        fetch_data_async(\"API 2\", 2),\n",
    "    )\n",
    "    print(\"Asynchronous Data Fetching End\")\n",
    "\n",
    "# Jupyter already runs an event loop in the background. This can cause conflicts when trying to start a new event loop using asyncio.run()\n",
    "await run_async_fetches()\n",
    "# asyncio.run(run_async_fetches())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "\n",
    "# async def fetch_data_async(api_name, delay):\n",
    "#     print(f\"Fetching data from {api_name} asynchronously... (delay: {delay} seconds)\")\n",
    "#     await asyncio.sleep(delay)\n",
    "#     print(f\"Received data from {api_name} asynchronously!\")\n",
    "\n",
    "\n",
    "# async def run_async_fetches():\n",
    "#     print(\"Asynchronous Data Fetching Start\")\n",
    "#     await asyncio.gather(\n",
    "#         fetch_data_async(\"API 1\", 3),\n",
    "#         fetch_data_async(\"API 2\", 2),\n",
    "#     )\n",
    "#     print(\"Asynchronous Data Fetching End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-5' coro=<run_async_fetches() running at /tmp/ipykernel_143328/2577022757.py:9>>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asynchronous Data Fetching Start\n",
      "Fetching data from API 1 asynchronously... (delay: 3 seconds)\n",
      "Fetching data from API 2 asynchronously... (delay: 2 seconds)\n",
      "Received data from API 2 asynchronously!\n",
      "Received data from API 1 asynchronously!\n",
      "Asynchronous Data Fetching End\n"
     ]
    }
   ],
   "source": [
    "# Jupyter already runs an event loop in the background. This can cause conflicts when trying to start a new event loop using asyncio.run()\n",
    "# def run_async_in_notebook(coroutine):\n",
    "#     loop = asyncio.get_event_loop()\n",
    "#     if loop.is_running():\n",
    "#         task = loop.create_task(coroutine)\n",
    "#         return task\n",
    "#     else:\n",
    "#         return loop.run_until_complete(coroutine)\n",
    "\n",
    "\n",
    "# run_async_in_notebook(run_async_fetches())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this asynchronous version, the `fetch_data_async` function uses `async` and `await` to define non-blocking behavior. `asyncio.gather` runs multiple asynchronous functions concurrently. This approach reduces the total wait time, demonstrating the efficiency of asynchronous programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to OpenAI API\n",
    "\n",
    "### Overview of OpenAI API\n",
    "The OpenAI API provides access to advanced AI models like GPT-3, offering capabilities in natural language processing. These models are adept at understanding and generating human-like text, making them valuable for applications like chatbots, translation, content creation, and more. One of the key features of the OpenAI API is its ability to handle streaming data, enabling real-time applications.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Interaction with OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import openai\n",
    "VARIABLE_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI(\n",
    "  api_key=VARIABLE_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('10 Academy is a not-for-profit initiative that provides effective training '\n",
      " 'programs to place young Africans into high-paying tech jobs for the 4th '\n",
      " 'Industrial Revolution.')\n"
     ]
    }
   ],
   "source": [
    "def query_openai(query, data):\n",
    "    completion = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": f\"You are a redash visualization assistant. \\n This data includes information about a company so address yours question regarding to the data in a proffessional manner: {data}\"},\n",
    "                    {\"role\": \"user\", \"content\": query }\n",
    "                ]\n",
    "            )\n",
    "    answer = completion.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "data = \"\"\"\n",
    "10 Academy is a not-for-profit community-owned initiative that has developed scalable, financially sustainable, and effective training programs to place young Africans into careers for the 4th Industrial Revolution.\n",
    "\n",
    "10 Academy focuses on creating pathways for young Africans to secure high-paying and relevant tech jobs. With a 37.5% representation of women among our graduates, we have already helped 176 individuals across Africa find improved employment. Our commitment remains strong for the next cohort of learners.\n",
    "\n",
    "10 Academyâ€™s vision is that youth in Africa will have a rich set of pathways to secure decent, impactful, and highly multiplicative employment with social, economic, and environmental benefits.\n",
    "\"\"\"\n",
    "# Example query\n",
    "# query_result = query_openai(\"Translate the following English text to French: 'Hello, how are you?'\", data)\n",
    "query_result = query_openai(\"What does 10academy do in one line sentence?'\", data)\n",
    "pprint(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code demonstrates a basic query to the OpenAI API, where we send a prompt for translation. Note the usage of `openai.Completion.create()` to interact with the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Redash\n",
    "\n",
    "### What is Redash?\n",
    "Redash is an open-source tool for querying, visualizing, and sharing data. It supports various data sources and is designed to democratize data access across organizations. Redash's primary function is to facilitate data exploration through SQL queries, visualization of results, and dashboard creation.\n",
    "\n",
    "### Asynchronous Tasks in Redash\n",
    "Asynchronous tasks in Redash are important for handling large datasets or complex queries. This can improve user experience by allowing the UI to remain responsive while data operations are processed in the background.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Sample Asynchronous Data Query in Redash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from asynchronously... (delay: 2 seconds)\n",
      "Data fetched\n",
      "Process Ended\n",
      "Result of query 12345\n"
     ]
    }
   ],
   "source": [
    "async def async_redash_query(query_id):\n",
    "    # In practice, make an async HTTP request to the Redash API\n",
    "    # Here, we simulate a delay for a long-running query\n",
    "    print(f\"Fetching data from asynchronously... (delay: 2 seconds)\")\n",
    "    await asyncio.sleep(2)  # Simulating a long-running query\n",
    "    print(f\"Data fetched\")\n",
    "    return f\"Result of query {query_id}\"\n",
    "\n",
    "\n",
    "async def main():\n",
    "    query_result = await async_redash_query(12345)\n",
    "    print(f\"Process Ended\")\n",
    "    print(query_result)\n",
    "\n",
    "\n",
    "# run_async_in_notebook(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we demonstrate how to perform an asynchronous query to Redash, simulating a long-running operation. This method allows other operations to continue while waiting for the query to complete.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Celery\n",
    "\n",
    "### Understanding Celery\n",
    "Celery is a distributed task queue that excels in handling asynchronous tasks and scheduling in web applications. It is particularly useful for long-running operations, enabling these tasks to be processed in the background, independent of the main application flow. This separation enhances performance and responsiveness.\n",
    "\n",
    "### Key Features\n",
    "- **Distributed Nature**: Manage tasks across multiple worker nodes.\n",
    "- **Support for Multiple Brokers**: Compatible with various message brokers like RabbitMQ, Redis.\n",
    "- **Task Scheduling**: Ability to schedule and execute tasks at a later time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Basic Setup with Celery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks submitted. Waiting for results...\n",
      "Multiplication Result: 12\n",
      "Addition Result: 8\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from celery.result import AsyncResult\n",
    "from celery_app import add, multiply\n",
    "\n",
    "# Submit tasks to Celery\n",
    "result_add = add.delay(4, 4)\n",
    "result_multiply = multiply.delay(6, 2)\n",
    "\n",
    "\n",
    "async def get_result_async(celery_result: AsyncResult, task_name: str):\n",
    "    while not celery_result.ready():\n",
    "        await asyncio.sleep(1)  # Wait for 1 second before checking again\n",
    "    result = celery_result.get()\n",
    "    print(f\"{task_name} Result: {result}\")\n",
    "\n",
    "\n",
    "async def main():\n",
    "    print(\"Tasks submitted. Waiting for results...\")\n",
    "    # Run both get_result_async concurrently\n",
    "    await asyncio.gather(\n",
    "        get_result_async(result_add, \"Addition\"),\n",
    "        get_result_async(result_multiply, \"Multiplication\"),\n",
    "    )\n",
    "\n",
    "\n",
    "# run_async_in_notebook(main())\n",
    "await(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we demonstrate a basic task queue using Celery. The `add` function, defined as a Celery task, is submitted for execution with `add.delay()`. The `result.get(timeout=10)` retrieves the task outcome, showcasing how Celery handles background tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Redis as a Message Broker and Result Backend\n",
    "- **Redis**: An in-memory data structure store, often used with Celery as a message broker and result backend.\n",
    "- **Role in Celery**: Facilitates the queuing of tasks and storage of their results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE\n",
    "----------------------------------------------------\n",
    "using async/await directly is more suitable for writing asynchronous code within a single application or coroutine context. It allows you to write non-blocking code and leverage the benefits of asynchronous programming when interacting with I/O-bound operations like network requests or file I/O.\n",
    "\n",
    "While async/await is powerful for writing asynchronous code, it doesn't provide the same level of distributed task execution, task management, and scaling capabilities as Celery. If your application requires distributed task processing, task queues, or scalability across multiple workers, Celery is a more suitable choice.\n",
    "\n",
    "In some cases, you might even combine Celery and async/await together. For example, you can use Celery to manage and distribute tasks across workers and leverage async/await within the task implementation to write asynchronous code when interacting with I/O-bound operations.\n",
    "\n",
    "Ultimately, the choice between using Celery or async/await directly depends on your specific application requirements and the nature of the tasks you need to execute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating OpenAI API Asynchronously\n",
    "\n",
    "### Efficient Handling of OpenAI API Requests\n",
    "Asynchronous integration of the OpenAI API is critical for handling multiple requests or streaming data efficiently. This approach can significantly improve the scalability and responsiveness of applications using the OpenAI API for natural language processing tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Streaming Responses with OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import ChatCompletion\n",
    "\n",
    "def get_response_stream(prompt):\n",
    "    # client = ChatCompletion()\n",
    "    response_stream = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=729,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "    )\n",
    "    return response_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `get_response_stream` function, we utilize the OpenAI ChatCompletion API with streaming enabled (`stream=True`). This function sets up a response stream for real-time data processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Streamed Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style='text-align: left;'><pre>As the spaceship soared through the galaxy, the crew marveled at the endless\n",
       "expanse of stars and planets. Suddenly, they received a distress signal from a\n",
       "nearby asteroid field and decided to investigate. They discovered a stranded\n",
       "alien ship and rescued the grateful extraterrestrial beings. In return, the\n",
       "aliens shared their advanced technology with the crew, allowing them to continue\n",
       "their journey with newfound knowledge and power. The crew returned to Earth as\n",
       "heroes, hailed for their bravery and ingenuity in the face of the unknown.</pre></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import textwrap\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "\n",
    "async def process_streamed_responses(response_stream):\n",
    "    response_text = \"\"\n",
    "    for chunk in response_stream:\n",
    "        chunk_message = chunk.choices[0].delta.content\n",
    "        if chunk_message is not None:  # Check if chunk_message is not None\n",
    "            response_text += chunk_message\n",
    "        is_complete = chunk.choices[0].finish_reason is not None\n",
    "        wrapped_text = textwrap.fill(response_text, width=80)  # Wrap text at 80 characters\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(f\"<div style='text-align: left;'><pre>{wrapped_text}</pre></div>\"))\n",
    "        if is_complete:\n",
    "            break\n",
    "\n",
    "\n",
    "async def main():\n",
    "    stream = get_response_stream(\"Tell me a story about a space adventure. in 5 line of sentence\")\n",
    "    await process_streamed_responses(stream)\n",
    "\n",
    "\n",
    "# run_async_in_notebook(main())\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The asynchronous function `process_streamed_responses` iterates over the OpenAI response stream, handling each response chunk as it arrives. This method is particularly useful for applications requiring real-time data processing, like chatbots or live content generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhancing Data Queries with Celery in Redash\n",
    "\n",
    "### Understanding the Collaboration\n",
    "Redash, known for its robust data visualization and analytics capabilities, effectively uses Celery to manage and execute data queries. This integration plays a crucial role in maintaining the efficiency and responsiveness of Redash, especially when dealing with complex and time-consuming data queries.\n",
    "\n",
    "### How Redash Uses Celery\n",
    "- **Background Query Execution**: Redash leverages Celery to run data queries in the background. This means that when a user executes a query, instead of waiting for the query to complete, the task is handed over to Celery.\n",
    "- **Task Queue Management**: Celery manages a queue of data query tasks. When a query is initiated, it is added to this queue and processed by available Celery workers.\n",
    "- **Asynchronous Processing**: By delegating query execution to Celery, Redash ensures that the main application thread remains unblocked, enhancing the user experience by preventing delays in the UI.\n",
    "\n",
    "### Advantages of this Integration\n",
    "- **Improved Performance**: Offloading query execution to Celery allows Redash to handle multiple queries more efficiently, enhancing overall performance.\n",
    "- **Scalability**: This setup enables Redash to scale more effectively, as additional worker nodes can be added to handle increased query load.\n",
    "- **Reliability**: By managing queries as background tasks, Celery provides a more robust and fault-tolerant system, as query execution is isolated from the main application logic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, `run_query` is a task defined in Redash that uses Celery. The `.delay` method submits the query to Celery's task queue for execution. The `task_result.get(timeout=20)` is used to retrieve the result, demonstrating how Redash handles asynchronous query execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Recap of Key Concepts\n",
    "- **Asynchronous Programming**: We delved into how asynchronous programming facilitates efficient, non-blocking operations, essential in handling I/O-bound tasks and improving the responsiveness of data-driven applications.\n",
    "- **OpenAI API**: Our exploration included basic interactions with the OpenAI API, emphasizing its potential in processing streaming responses asynchronously for real-time data analysis and query generation.\n",
    "- **Redash**: The role of Redash in data visualization and analytics was highlighted, with a particular focus on its ability to benefit from asynchronous data processing, enhancing its functionality in handling complex queries and large datasets.\n",
    "- **Celery**: We introduced Celery as a distributed task queue, essential for managing background tasks and processing heavy data operations, using Redis for efficient task queuing and result storage.\n",
    "\n",
    "### Applying These Concepts in the Week 3 Challenge\n",
    "- **Natural Language Driven Data Exploration**: The integration of the OpenAI API with Redash, as outlined in your project, allows for the translation of natural language queries into SQL, empowering users to interact with data intuitively. This application demonstrates the practical use of AI in enhancing user experience and data accessibility.\n",
    "- **Responsive Redash Add-Ons**: By applying asynchronous programming techniques, your Redash add-on can efficiently handle data queries and updates, ensuring a smooth and responsive user interface, even when processing complex data operations from YouTube, Slack, or Gmeet insights.\n",
    "- **Efficient Backend Systems**: Utilizing Celery for task management in your backend systems ensures that heavy data processing tasks, such as generating new SQL queries or updating dashboards, do not hinder the overall application performance.\n",
    "- **End-to-End Insight Extraction**: The challenge's goal of autonomous knowledge discovery is well-served by combining these technologies. Large Language Models (LLMs) can analyze and interpret user queries, Celery can manage the data processing workload, and Redash can present the insights in a user-friendly manner.\n",
    "\n",
    "### Encouragement for Integration and Experimentation\n",
    "I encourage you to leverage these technologies in your project for the Week 3 challenge. The synergy between asynchronous programming, AI-driven natural language processing, and efficient data management through Celery and Redash presents a robust framework. This integration not only enhances the user experience by providing real-time, interactive data exploration but also paves the way for innovative approaches in business intelligence and data analytics.\n",
    "\n",
    "Experiment with these components to see how they can be integrated into a cohesive system, enhancing your solution's capability to transform natural language inquiries into insightful data visualizations and actionable intelligence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
